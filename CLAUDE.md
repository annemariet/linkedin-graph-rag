# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

A Python client for LinkedIn's Portability API (DMA-compliant) that uses the API for selective reading of your own activity (posts, reactions, comments), builds a knowledge graph in Neo4j, and enables GraphRAG-powered semantic search. Data is obtained via the Portability API, not by scraping.

## Core Workflow

1. **Fetch LinkedIn Data** → Extract changelog activities via LinkedIn Portability API
2. **Build Knowledge Graph** → Import entities (People, Posts, Comments) and relationships into Neo4j
3. **Index Content** → Extract post/comment text, create embeddings, build vector index
4. **Query with GraphRAG** → Semantic search combining vector retrieval and graph traversal

## Development Commands

### Setup
```bash
# Install all dependencies (uses uv for dependency management)
uv sync

# Install with dev dependencies
uv sync --all-groups
```

### Authentication Setup
```bash
# Store LinkedIn token in macOS Keychain (recommended)
uv run python setup_token.py

# Check token validity
uv run python check_token.py
```

### Running Scripts
```bash
# Fetch LinkedIn changelog data and explore activities
uv run python -m linkedin_api.explore_changelog_details

# Build Neo4j graph from fetched data
uv run python -m linkedin_api.build_graph

# Index content for GraphRAG (with optional limit for testing)
uv run python -m linkedin_api.index_content
uv run python -m linkedin_api.index_content --limit 5

# Query GraphRAG (interactive mode)
uv run python -m linkedin_api.query_graphrag

# Query GraphRAG (command line)
uv run python -m linkedin_api.query_graphrag "What posts did I react to about AI?"
uv run python -m linkedin_api.query_graphrag --cypher "What are main topics in posts I commented on?"

# Verify GraphRAG indexing
uv run python -m linkedin_api.verify_indexing

# Launch Gradio web interface
uv run python -m linkedin_api.gradio_app

# Period-based activity collection (Phase 1)
uv run python -m linkedin_api.summarize_activity --from-cache -o activities.json
uv run python -m linkedin_api.summarize_activity --last 7d -o activities.json

# Enrich activities with post content via browser (Phase 2)
uv run python -m linkedin_api.enrich_activities activities.json -o activities_enriched.json
uv run python -m linkedin_api.enrich_activities activities.json --limit 5
```

### Testing
```bash
# Run all tests
uv run pytest

# Run tests with coverage
uv run pytest --cov=linkedin_api --cov-report=html

# Run specific test file
uv run pytest tests/test_changelog_utils.py

# Run tests in linkedin_api package
uv run pytest linkedin_api/tests/
```

### Linting & Formatting
```bash
# Format code with black
uv run black .

# Check formatting without modifying
uv run black --check .

# Run flake8
uv run flake8 linkedin_api tests examples *.py

# Run type checking with mypy
uv run mypy linkedin_api
```

### Pre-commit Hooks
```bash
# Install pre-commit hooks
uv run pre-commit install

# Run hooks manually
uv run pre-commit run --all-files
```

## Architecture

### Core Module Structure

All core scripts are designed as **dual-use modules**:
- **CLI tools**: Run directly with `uv run python -m <module>`
- **Importable modules**: Import functions/constants in other scripts

This avoids code duplication (e.g., `gradio_app.py` imports from `query_graphrag.py`).

### Key Modules

#### `linkedin_api/auth.py`
Handles LinkedIn API authentication:
- Retrieves tokens from macOS Keychain (preferred) or environment variables
- Falls back gracefully if keyring unavailable
- Builds authenticated `requests.Session` with proper headers

#### `linkedin_api/changelog_utils.py`
Shared utilities for fetching LinkedIn changelog data:
- `fetch_changelog_data()`: Paginated fetching with resource filtering
- Handles batching (default 50 items per request)
- Session management via `get_changelog_session()`

#### `linkedin_api/explore_changelog_details.py`
Extracts entities and relationships for Neo4j:
- Parses changelog data into People, Posts, Comments, Reactions
- Generates relationship tuples (e.g., `Person REACTS_TO Post`)
- Outputs `neo4j_data.json` for graph import
- Uses URN utilities for ID extraction and URL conversion

#### `linkedin_api/build_graph.py`
Loads graph data into Neo4j:
- Reads `neo4j_data.json` (generated by `explore_changelog_details.py`)
- Creates nodes with dynamic labels and properties
- Creates relationships with dynamic types
- Batched operations (500 items per batch)
- **Cleans database on run** (deletes all existing nodes)

#### `linkedin_api/index_content.py`
Indexes post/comment content for GraphRAG:
- Fetches Post/Comment nodes from Neo4j (content sourced from Portability API)
- Uses content from Neo4j; only fetches from post URLs when content is missing (e.g. legacy data)
- Splits text into chunks (500 chars, 100 char overlap)
- Generates embeddings via Google Vertex AI (`textembedding-gecko@002`)
- Creates Chunk nodes linked to source posts/comments
- Creates/updates vector index for retrieval
- Supports `--limit N` for quick testing

#### `linkedin_api/query_graphrag.py`
GraphRAG query interface (CLI + importable):
- **Exports**: `find_vector_index()`, `create_vector_retriever()`, `create_vector_cypher_retriever()`, configuration constants
- Two retrieval modes:
  - **Vector**: Fast semantic search over chunk embeddings
  - **Vector+Cypher**: Combines vector search with graph traversal for relationship context
- Interactive mode (default) or command-line mode
- Commands: `cypher` (toggle retriever), `topk <N>` (set result count), `quit/exit`

#### `linkedin_api/gradio_app.py`
Web UI for GraphRAG queries:
- **Imports functions from `query_graphrag.py`** (no code duplication)
- Handles GCP credentials from environment variables
- Respects `$PORT` for cloud deployment (Scalingo)
- Uses `if __name__ == "__main__"` guard for clean imports

#### `linkedin_api/urn_utils.py`
URN parsing and URL conversion:
- Extracts IDs from LinkedIn URNs
- Converts URNs to public LinkedIn URLs
- Handles various URN formats (posts, comments, people)

#### `linkedin_api/summary_utils.py` & `linkedin_api/activity_utils.py`
Helper utilities for analyzing/summarizing LinkedIn changelog data.

### Data Flow

```
LinkedIn API
    ↓ (fetch_changelog_data)
Changelog JSON
    ↓ (explore_changelog_details.py)
neo4j_data.json
    ↓ (build_graph.py)
Neo4j Graph (People, Posts, Comments, Reactions)
    ↓ (index_content.py)
Chunk Nodes + Embeddings + Vector Index
    ↓ (query_graphrag.py / gradio_app.py)
GraphRAG Queries
```

### Neo4j Graph Schema

**Nodes:**
- `Person`: `urn`, `person_id`
- `Post`: `urn`, `post_id`, `url`, `created_at`
- `Comment`: `urn`, `comment_id`, `url`, `created_at`, `text`
- `Chunk`: `text`, `embedding`, `chunk_index` (linked to Posts/Comments)

**Relationships:**
- `Person -[:REACTS_TO {reaction_type, timestamp}]-> Post`
- `Person -[:COMMENTS_ON {timestamp}]-> Post`
- `Person -[:REPOSTS {timestamp}]-> Post`
- `Person -[:CREATES]-> Post`
- `Comment -[:ON_POST]-> Post`
- `Chunk -[:FROM_CHUNK]-> Post/Comment`

## Environment Variables

Required for API access:
```bash
LINKEDIN_ACCESS_TOKEN=your_token_here
LINKEDIN_ACCOUNT=your_email@example.com  # Used as keyring account
```

Required for Neo4j:
```bash
NEO4J_URI=neo4j://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_password
NEO4J_DATABASE=neo4j  # Default
```

Required for GraphRAG (Google Vertex AI):
```bash
GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json
EMBEDDING_MODEL=textembedding-gecko@002  # Default (stable, lightweight)
LLM_MODEL=gemini-1.5-pro  # Default
VECTOR_INDEX_NAME=linkedin_content_index  # Default
```

For deployment (Scalingo/cloud):
```bash
PORT=7860  # Overrides default Gradio port
```

## Token Management

LinkedIn access tokens expire every ~60 days. When you see:
```json
{"status":401,"serviceErrorCode":65602,"code":"EXPIRED_ACCESS_TOKEN","message":"The token used in the request has expired"}
```

Recreate token at https://www.linkedin.com/developers/tools/oauth and update via:
```bash
uv run python setup_token.py
```

## Important Notes

### LinkedIn Portability API
- Uses `r_dma_portability_self_serve` OAuth scope
- Subject to rate limits
- Only accesses user's own content (DMA-compliant)
- API reference: https://learn.microsoft.com/en-us/linkedin/dma/member-data-portability/

### Code Style
- Python 3.12+ required
- Black formatter (line length: 88)
- Flake8 linting (ignores E203, W503)
- Type hints preferred (mypy configured but non-blocking)
- Pre-commit hooks enforce formatting and conventional commits

### Module Design Principles
1. **Guard main execution**: All scripts use `if __name__ == "__main__":`
2. **Export reusable functions**: Make functions importable
3. **No code duplication**: Import from existing modules (see `gradio_app.py` ← `query_graphrag.py`)
4. **Configuration constants**: Export at module level for importers
5. **Clean entry points**: Define `main()` functions for CLI usage

### Neo4j Operations
- `build_graph.py` **clears the database** before loading
- Batched operations (500 nodes/relationships per batch)
- Standard Cypher queries (no custom APOC procedures required for loading)
- Vector indexes require Neo4j 5.0+ with vector search support

### GraphRAG Limitations
- Content extraction from LinkedIn URLs requires public accessibility
- Content is primarily from the Portability API; URL fetch is only a fallback and may not work for all posts (basic HTML parsing)
- Embedding generation fails fast (no silent errors)
- Vector index dimensions must match embedding model (768 for gecko)

## Deployment

The project supports Scalingo deployment via Gradio:
- `Procfile`: `web: uv run python -m linkedin_api.gradio_app`
- `runtime.txt`: Specifies Python 3.12
- See `SCALINGO_DEPLOYMENT.md` for detailed deployment instructions

## Testing Strategy

- Unit tests in `tests/` and `linkedin_api/tests/`
- Integration tests marked with `@pytest.mark.integration`
- Test configuration in `pyproject.toml`
- Coverage configured to omit test files and examples
- CI/CD via GitHub Actions (`.github/workflows/python-package.yml`)

## DNS Fix for GCP

The codebase includes a DNS fix for Google Cloud Platform connectivity issues:
- `linkedin_api/dns_utils.py` (if present)
- Applied before importing Google libraries in GraphRAG modules
- See `DNS_VPN_FIX.md` for details
